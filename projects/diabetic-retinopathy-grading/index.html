<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Vinay Ummadi | Diabetic Retinopathy Recognition</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="../../assets/img/favicon.png">
<link rel="stylesheet" href="../../assets/css/main.css">

<link rel="canonical" href="projects">

<!-- Theming-->

<style>
    table, td, th {
      border: 1px solid;
    }
    td,th {
      text-align: center;
    }

    th{
        font-weight: bold;
        font-size: 1.2em;
    }
    
    td {
        font-size: 12px;
    }
    table {
      width: 90%;
      border-collapse: collapse;
    }
</style>
    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="../">
       <span class="font-weight-bold">Vinay</span>   Ummadi
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <!-- <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li> -->
          <li class="nav-item ">
            <a class="nav-link" href="../../">Home</a>
          </li>
          
          <!-- Other pages -->
          
          <li class="nav-item active">
              <a class="nav-link" href="../">
                Projects
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          <!--
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications">
                Publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/patents">
                Patents
                
              </a>
          </li>
          
          
          -->
          
          
          <li class="nav-item ">
              <a class="nav-link" href="../../bio">
                Bio/CV
                
              </a>
          </li>
          
          
          <!-- <li class="nav-item ">
            <a class="nav-link" href="/pdfs/Utkarsh_CV.pdf" download>
              Download CV
              
            </a>
        </li> -->
          
        </ul>
      </div>
    </div>
  </nav>

</header>

    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h3 class="post-title" align="center">Diabetic Retinopathy Grading </h3>
    <!-- <p class="card-text">Current and past projects that I have been a part. Click on each project to know more</p> -->
  </header>

  <article>
    <div class="projects mt-4">
        <!-- The project text starts from here -->
    
    <!-- Brief introduction to the problem -->
    <div class="container">
        <h4 class="category"> Brief Description</h4>
        <p class="card-text">
            This project is a term project for Medical Image Analysis course offered in Spring 2022 by Prof Nirmalya Ghosh at IIT Kharagpur. 
            Sneha and I teamed up to complete this project.
        </p>

        <p class="card-text">
            The final report of the project can be accesible from here : <a class="authorlink" target="_blank" href="Diabetic_Retinopathy_Reccognition___Class_Project_for_Medical_Image_Analysis.pdf">Report</a>
        </p>

        <p class="card-text">
            The final slides of the project can be accesible from here : <a class="authorlink" target="_blank" href="Diabetic Retinopathy Recognition & Classification.pdf">Slides</a>
        </p>

        <p class="card-text">
            <!-- Just create some space before the new section -->
        </p>

    </div>

    <!-- defining the problem -->
    <div class="container">
        <h4 class="category"> Problem</h4>
        <p class="card-text">
            Diabetic Retinopathy is a complication of diabeties that effect eye. DR is the major cause of blindness in India, which accounts for 30% of DR cases in the world. 
            Early diagnosis of DR can reduce the risk of blindness by 90%. Causes for DR can be identified using the following features:

            <ol type="1">
                <li>Hemmorages</li>
                <li>Exudates</li>
                <li>Abnormal growth of blood vessels</li>
            </ol>
                    
                    
                    Now lets see how DR can be classified into different types. The following table shows the classification of DR.
                    <p>

                    </p>

                    <table style="width:100%" align="center">
                        <caption style="text-align:center">Model interpretation for each class using <b>Integrated Gradients</b> and <b>DeepLIFT</b><caption>
                    
                        <tr>
                            <th>Class and Label</td>
                            <td><b>No DR - 0</b></td>
                            <td><b>Mild - 1</b></td>
                            <td><b>Moderate -2</b></td>
                            <td><b>Severe - 3</b></td>
                            <td><b>Proliferate - 4</b></td>
                        </tr>

                        <tr>
                            <th>Image</th>
                            <td><img class="p-1" src="class_images/nodr.png" alt="No DR" width="150" height="150"></td>
                            <td><img class="p-1" src="class_images/mild.png" alt="No DR" width="150" height="150"></td>
                            <td><img class="p-1" src="class_images/moderate.png" alt="No DR" width="150" height="150"></td>
                            <td><img class="p-1" src="class_images/severe.png" alt="No DR" width="150" height="150"></td>
                            <td><img class="p-1" src="class_images/proliferative.png" alt="No DR" width="150" height="150"></td>
                        </tr>

                        <tr>
                            <th>Description</th>
                            <td>No presence of DR features. Clean Eye</td>
                            <td>At least one microaneurysm present on retinal exam</td>
                            <td>Multiple microaneurysms, dot-and-blot hemorrhages, venous beading, and/or cotton wool spots</td>
                            <td>Cotton wool spots, venous beading, and severe intraretinal microvascular abnormalities (IRMA)</td>
                            <td>Growth of new blood vessels, Blood vessels bleeding, Retinal detachment</td>
                        </tr>
                    </table>
        </p>

        <p>
            
        </p>
    </div>

    <!-- Implemented Methods -->

    <div class="container">
        <h4 class="category"> Methods </h4>

        <h5 class="category"> Method 1 : Deep Feature Extraction + External Classification </h5>
        <p class="card-text">
            The first method was to extract features from the images using pretrained model Inception V3. 
            Inception V3 is trained on the ImageNet dataset and can be used as a feature extractor.The extracted features are used as inputs to difeerent ML classifiers. 
            The statistical results are tabulated for each classifier with and without data augumentation.
        </p>

        <table style="width:70%" align="center">
            <caption style="text-align:center">Evalution metrics for DR binary classification - <b>without data augumentation</b></caption>
            <tr>
                <th>Classifier</th>
                <th>Accuracy</th>
                <th>Precision</th>
                <th>Recall</th>
                <th>F1 Score</th>
            </tr>

            <tr>
                <td>KNN</td>
                <td>0.7848</td>
                <td>0.79</td>
                <td>0.78</td>
                <td>0.78</td>
            </tr>

            <tr>
                <td>SVM</td>
                <td>0.7818</td>
                <td>0.78</td>
                <td>0.78</td>
                <td>0.78</td>
            </tr>


            <tr>
                <td>Random Forest</td>
                <td>0.8091</td>
                <td><b>0.81</b></td>
                <td><b>0.81</b></td>
                <td><b>0.81</b></td>
            </tr>

            <tr>
                <td>XGBoost</td>
                <td><b>0.8121</b></td>
                <td><b>0.81</b></td>
                <td><b>0.81</b></td>
                <td><b>0.81</b></td>
            </tr>

            <tr>
                <td>DNN</td>
                <td>0.7787</td>
                <td>0.77</td>
                <td>0.77</td>
                <td>0.77</td>
            </tr>

        </table>

        <p class="card-text">
            From the results above that it is clear that Random Forest and XGBoost are performing well but XGBoost is outperforming by a slight marging. 
            As we all know we can let the model learn image invariances and which can be lead to an improved performance.
            The following data augumentation are performed to increase the performance of the model.
            <ul>
                <li>
                    Rotation
                </li>

                <li>
                    Resizing    
                </li>

                <li>
                    Gaussian Noise
                </li>

                <li>
                    Histogram Equalization
                </li>
            </ul>
        </p>

        <p class="card-text">
            The results of the model with data augumentation are as follows.
            <table style="width:70%" align="center">
                <caption style="text-align:center">Evalution metrics for DR binary classification - <b>with data augumentation</b></caption>
                <tr>
                    <th>Classifier</th>
                    <th>Accuracy</th>
                    <th>Precision</th>
                    <th>Recall</th>
                    <th>F1 Score</th>
                </tr>
    
                <tr>
                    <td>KNN</td>
                    <td>0.9064</td>
                    <td>0.90</td>
                    <td>0.90</td>
                    <td>0.90</td>
                </tr>
    
                <tr>
                    <td>SVM</td>
                    <td>0.9102</td>
                    <td>0.91</td>
                    <td>0.91</td>
                    <td>0.91</td>
                </tr>
    
    
                <tr>
                    <td>Random Forest</td>
                    <td>0.9707</td>
                    <td>0.97</td>
                    <td>0.97</td>
                    <td>0.97</td>
                </tr>
    
                <tr>
                    <td>XGBoost</td>
                    <td>0.9707</td>
                    <td>0.97</td>
                    <td>0.97</td>
                    <td>0.97</td>
                </tr>
    
                <tr>
                    <td>DNN</td>
                    <td><b>0.9757</b></td>
                    <td>0.97</td>
                    <td>0.97</td>
                    <td>0.97</td>
                </tr>
    
            </table>
        
        Our data augumentaions worked well and significantly impoved the performance of the models. 
        It is obivoius from the results that the DNN is the best performing classifier with <b>97.57%</b> accuracy. 
        Now we will look into different deep neural networks for end-to-end classification. 
        Remember that we have not yet done the our main problem multi class classification.
        </p>

        <h5 class="category"> Method 2 : End-to-End Deep Neural Net based Classification</h5>
        <p class="card-text">
            Now our approach is to use the state of the art deep neural networks for end-to-end classification. 
            For this task we can go with either fine-tuning or traning from scratch.
            <ul>
            
                <li>
                    <b>Training from scratch</b> : This method work well only if we had a large set of images (but we have only 2667 for training for binary classification and 2963 for multi class classification)
                </li>

                <li>
                    <b>Fine-tuning</b> : This methods works well even if we have a small set of images(2667 and 2963 are good enough to produce reasonable results). 
                    All fine tuning models are trained on ImageNet dataset which is a large dataset with over 1 million images and 1000 categories.
                </li>
            </ul>

            The following architectures are used with mentioned hyperparamenters and training reciepe.
            <ol>
                <li>
                    <b>VGG</b> - VGG19 is a standard 19 layer convnet with that achieved SOTA results on ImageNet in 2013. 
                    Commonly used as a feature extractor for downstream tasks such as image classification, detection, segmentation etc.
                </li>

                <li>
                    <b>ResNet</b> - ResNet is a builds upon VGG network. 
                    It utilizes skip connections to jump over layer that help in gradient propagation, local - global feature interactions. 
                    We will be using ResNet18 with 18 convolutional layers.
                </li>
                <li>
                    <b>EfficinetNet</b> : EfficientNet builds upon basis that appropriate depth, width and resolution of the networks are essential for best performance. 
                    It uses a depth, width, resolution scaling factor to develop a network that is efficient for a given task. 
                    We will be using EfficientNetB0 which is a base network.        
                </li>

                <li>
                    <b>ConvNext</b> : After Visual Transformers, convnext uses the best practices from both natural language and vision to create a set of convnext variants. 
                    ConvNext are current state of the art convolutional neural networks for image classification on benchmark dataset ImageNet. 
                    We will be using ConvNext-Tiny variant for this task.
                </li>
            </ol>

            The models are trained on a <b>Tesla T4 GPU (16GB memory)</b> on AWS Sagemaker Studio Lab. 
            <b>Binary/Categorical Cross Entropy</b> loss is used as cost function to penalize the false classifications. 
            <b>Adaptive momentum (Adam)</b> optimizer with <b>learning rate = 3e-4</b> and <b>momentum = 0.9</b> is used to optimize the error. 
            Batch size is chosen appropriately so that capacity of the GPU is not exceeded. Used batch sizes are <b>32</b>, <b>64</b> and <b>128</b>.


        </p>

        <p class="card-text">
            
            We have tried with training from scratch but that doesn't gone well. If had time I'll try post those results as well(I have re-run the experiments to get the results). 
            The maximum accuracy achieved with the training from scratch is <b>~90%</b> .

            Now we will fine-tune pretrained layers to match the number of classes. 
            Following are the results for binary classification ({<b>No DR</b>, <b>DR</b>}) and multi class classification ({<b>No DR</b>, <b>Mild DR</b>, <b> Moderate DR</b>, <b>Severe DR</b>, <b>Proliferate DR</b>}) using fine-tuning .


            <table style="width:70%" align="center">
                <caption style="text-align:center">Evalution metrics for <b>binary DR classification - using fine-tuning</b></caption>
                <tr>
                    <th>Model</th>
                    <th>Accuracy</th>
                    <th>Precision</th>
                    <th>Recall</th>
                    <th>F1 Score</th>
                    <th>False classifications(out of 800)</th>
                </tr>
    
                <tr>
                    <td>VGG19</td>
                    <td>0.977</td>
                    <td>0.98</td>
                    <td>0.98</td>
                    <td>0.98</td>
                    <td>18</td>
                </tr>

                <tr>
                    <td>ResNet18</td>
                    <td>0.974</td>
                    <td>0.97</td>
                    <td>0.97</td>
                    <td>0.97</td>
                    <td>21</td>
                </tr>

                <tr>
                    <td>EfficientNet-B0</td>
                    <td>0.974</td>
                    <td>0.97</td>
                    <td>0.97</td>
                    <td>0.97</td>
                    <td>21</td>
                </tr>
    
    
                <tr>
                    <td>ConvNext-Tiny</td>
                    <td><b>0.981</b></td>
                    <td>0.98</td>
                    <td>0.98</td>
                    <td>0.98</td>
                    <td><b>13</b></td>
                </tr>
    
            </table>

            From the above results we can see that <b>ConvNext-Tiny</b> is the best performing model for binary classification with an accuracy of <b>0.981</b> and only <b>13</b> false classifications out of 800..

            <table style="width:70%" align="center">
                <caption style="text-align:center">Evalution metrics for <b>Multi class DR classification - using fine-tuning</b></caption>
                <tr>
                    <th>Model</th>
                    <th>Accuracy</th>
                    <th>Precision</th>
                    <th>Recall</th>
                    <th>F1 Score</th>
                    <th>False classifications(out of 704)</th>
                </tr>
    
                <tr>
                    <td>VGG19</td>
                    <td>0.9644</td>
                    <td>0.96</td>
                    <td>0.92</td>
                    <td>0.94</td>
                    <td>25</td>
                </tr>

                <tr>
                    <td>ResNet18</td>
                    <td>0.99</td>
                    <td>0.98</td>
                    <td>0.98</td>
                    <td>0.98</td>
                    <td>7</td>
                </tr>

                <tr>
                    <td>EfficientNet-B0</td>
                    <td><b>0.997</b></td>
                    <td>0.99</td>
                    <td>0.99</td>
                    <td>0.99</td>
                    <td><b>2</b></td>
                </tr>
    
    
                <tr>
                    <td>ConvNext-Tiny</td>
                    <td>0.995</td>
                    <td>0.99</td>
                    <td>0.99</td>
                    <td>0.99</td>
                    <td>3</td>
                </tr>
    
            </table>

            From the above results we can see that <b>EfficientNet-B0/b> is the best performing model for multi class classification with an accuracy of <b>0.997</b> and only <b>2</b> false classifications out of 704.
        </p>


    </div>

    <h5 class="category">Model Understanding</h5>

    <p>
        We just not only want a model that can classify DR but give reasonings for the classifications. 
        There are quite a few popular methods that can be used to understand the model. 
        We will be using <b>Visual Explanations</b> to understand the model. 
        We'll see Saliency Maps, Gradient based Attributions, DeepLIFT, Guided Backpropagation.

        The following table shows the outputs of visual explanations from the model.

        <table style="width:100%" align="center">
            <caption style="text-align:center">Model interpretation for each class using <b>Integrated Gradients </b> and <b>DeepLIFT</b></caption>
        
            <tr>
                <th><b>Class</b> </td>
                <th><b>Input Image</b></th>
                <th><b>Overlayed Gradient Magnitudes</b></th>
                <th><b>Overlayed Integrated Gradients</b></th>
                <th><b>DeepLIFT</b></th>
            </tr>

            <tr>
                <th>Mild DR</th>
                <td><img class="p-1" src="interpret/1_Mild_org.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/1_Mild_grads.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/1_Mild_attr_ig.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/1_Mild_attr_dl.png" alt="No DR" width="250" height="250"></td>
            </tr>

            <tr>
                <th>Moderate DR</th>
                <td><img class="p-1" src="interpret/2_Moderate_org.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/2_Moderate_grads.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/2_Moderate_attr_ig.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/2_Moderate_attr_dl.png" alt="No DR" width="250" height="250"></td>
            </tr>

            <tr>
                <th>Severe DR</th>
                <td><img class="p-1" src="interpret/3_Severe_org.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/3_Severe_grads.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/3_Severe_attr_ig.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/3_Severe_attr_dl.png" alt="No DR" width="250" height="250"></td>
            </tr>

            <tr>
                <th>Proliferate DR</th>
                <td><img class="p-1" src="interpret/4_Proliferate_DR_org.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/4_Proliferate_DR_grads.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/4_Proliferate_DR_attr_ig.png" alt="No DR" width="250" height="250"></td>
                <td><img class="p-1" src="interpret/4_Proliferate_DR_attr_dl.png" alt="No DR" width="250" height="250"></td>
            </tr>

            
        </table>

        From the above attributions we can understand where the model is looking to produce a classification result.
        
    </p>
    
    

    <div class="container">
        <h4 class="category"> Conclusion </h4>
        <p class="card-text">
            The obtained results indicate that modern deep networks outperform traditional methods by significant margins (without data augmentation).              
                
            The are train and test set are obtained from the <a class="authorlink" target="_blank" href="https://www.kaggle.com/c/aptos2019-blindness-detection/data">APTOS 2019 Blindness Detection</a> dataset.
                    
            The shown results are not representative of the real world. The results are obtained on a small dataset.

            Given that 99.8% accuracy doesn't mean that DR recognition problem is solved. The accuracy is only very small set of images that are not representative of the real world scenarios.
            
            There are still gaps exists in taking these models to the real world. Following are the list of few(out of many) problems.
        
            <h5 class="category"> Probelms </h5>
            <ol>
                <li>
                    Expert labes are very costly. Hoping to create a large dataset(Millions of images) with expert labels is unfeasible task.
                </li>
                <li>
                    Noisy labels create a mess for the models. The quality of the model is of prime importance. 
                </li>

                <li>
                    Data bias is a huge probelm in medical domain. Models are being trained on single dataset which is collected from one source / hospital / region. 
                    This induces the local bias in the model. The model performance then never matters if it can work well on differnent dataset.
                </li>
            </ol>    

            <h5 class="category"> Forward directions </h5>
            Currently the researchers are working towards the following solutions.
            <ol>
                <li>
                    Since expert labels costly. Developing robust and high performance Unsupervised / Semisupervised alogrithms can be a game changer.
                </li>
                <li>
                    Training the models on multiple dataset can make model more robust. Federated Learning can be used to train the models on multiple datasets. 
                    In federated learning, the model is trained using distributed and centralized process where data is securely stored at its origin. 
                </li>
            
        </p>
    </div>
  
  <!-- Display categorized projects -->
    
      
      
    

  

</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container justify-content-center">
    &copy; Inspired by UD webpage, Copyright 2022 @ <b>Vinay</b> Ummadi.
    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="../../assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-131556520-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-131556520-1');
</script>


<!-- Load Common JS -->
<script src="../assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="../../assets/js/dark_mode.js"></script>


</html>

